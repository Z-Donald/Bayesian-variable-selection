来源: [http://www.kev-smith.com/tutorial/rjmcmc.php](http://www.kev-smith.com/tutorial/rjmcmc.php)

# RJMCMC

## 多目标录像追踪

通过分析一个或者多个照相机的录像输出来定位不定数量的目标. 

## 建模: 动态贝叶斯网络

动态贝叶斯网络是一个有向无环图. 

[图模型是通过图结构来展示随机变量之间的依赖关系, 其中, 点表示随机变量, 边表示点之间的条件依赖. ]

多目标追踪的方法中, 图结构中有两类随机变量. 第一种是表示多目标的配置, 我们记为$X$. 多目标的配置通过一组参数描述了目标在场景中的状态(可能包括索引, 位置, 高, 宽, 形状等). 这些参数时未知的, 追踪则是从我们可以观察到的东西中估计出这些参数. 图模型中的另一种随机变量表示观测, 我们记为$Z$. 尽管多目标配置是未知的, 但是观测展示了什么是已知的. 对于可视化追踪, 观测意味着从图像中提取出来的信息. 

多目标配置$X$代表了我们所追踪的目标的真实状态, 而观测$Z$代表我们从场景中所能够观察到的信息. 直观上来说, 我们可以说观测依赖于多目标的真实配置. 

到此为止, 我们定义了$X$和$Z$来刻画单个图像的多目标物体的配置以及观测, 但是我们关心的却是追踪一系列的图像. 为了对一系列的图像进行建模, 我们建立了包含长为t = {1, ..., T}的单个图像模型的图模型. 为了与单个图模型建立联系, 我们做了一个马尔科夫链假设, 即假设t时刻多目标配置$(X_t)$仅仅依赖于前一时刻的配置$X{t-1}$. 换句话说, 

## 解决方案: 递归的贝叶斯滤波

在贝叶斯方法中, 我们通过对依赖的图结构概率建模解决追踪问题. 本质上, 我们是从数学 的角度上提出问题: 给定过去和现在的观测信息后, 一个多目标配置的概率是多少, 即$P(X_t|Z_{1:t})$.

$P(X_t|Z_{1:t})$是一个概率密度函数(pdf), 叫做后验. 思考后验pdf的另一种方式是在知道所有过去个现在图像信息时, 每个现在可能的多目标配置的概率集合. 一些配置比其他的更加有可能发生. 

后验pdf代表了目标状态的信念, 这是解决追踪问题的关键. 使用可逆的贝叶斯推断过程来寻找后验pdf. 使用图模型中的依赖结构, 这个过程定义了一系列的等式来描述后验. 递归贝叶斯推理有两个步骤. 第一步是预测, 即基于多目标的前一个配置和观测预测一个新的多目标配置:

$ p(X_t|Z_{1:t-1}) = \int p(X_t|X_{t-1})p(X_t|Z_{1:t-1})dX_{t-1}$

第二步, 更新, 来自于贝叶斯理论, 并且根据等式1的预测给出了后验pdf,

$p(X_t|Z_{1:t}) = \frac{p(Z_t|X_t)p(X_t|Z_{1:t})}{p(Z_t|Z_{1:t})}$

等式2的分母$p(Z_t|Z_{1:t})$是一个常数, 因为一个观测和其他的观测是独立的. 如果我们称这一常数项为C并且将式1带入式2, 我们得到了一个后验pdf的表达式, 记为递归贝叶斯滤波分布:

$p(X_t|Z_{1:t})=C^{-1}p(Z_t|X_t)\times\int_{X_t-1}p(X_t|X_{t-1})p(X_{t-1}|Z_{1:t-1})dX_{t-1}$

这个等式根据三个pdf给出了后验pdf, 简要地描述如下:

1. $p(Z_t|X_t)$ 似然: 似然衡量了给定一组观测后一个提议多目标配置的可能性. 考虑可能性的另一种方法是衡量观察结果如何支持关于目标的当前状态的假设.
2. $p(X_t|X_{t-1})$ 演变: 状态演变, 或者状态的动态, 控制着随时间变化多目标配置的演变. 它从前一状态$X_{t-1}$预测当前状态$X_t$.  状态演变负责对运动, 形状变化和对象间的交互建模. 
3. $p(X_{t-1}|Z_{1:t-1})$ 先验: 先验是前一个时间点的后验pdf. 这一项提供了过去的知识, 给出了递归贝叶斯滤波分布的一个参考框架来预测当前状态. 

对于某些情况, 可以直接计算递归贝叶斯滤波分布(当一切都是线性和高斯).  在这种情况下, 该模型相当于卡尔曼滤波器. 不幸的是, 视觉跟踪通常是高度非线性的和非高斯的, 所以我们必须找到一种方法来近似等式3的递归贝叶斯滤波分布. 

## 通过MCMC来近似

马尔科夫链蒙特卡罗(MCMC)方法将等式3的递归贝叶斯滤波分布近似为一组称为马尔可夫链的离散样本.  为了做到这一点, 我们遵循蒙特卡洛近似, 其中先验(t-1时刻的后验pdf)由一组N个样本近似, 每个样本包含关于多目标配置的假设$\{X_t^{(n)}, n=1, ..., N\}$. 

$p(X_{t-1}|Z_{1:t-1})\approx\sum\limits_n\delta(X_{t-1} - X_{t-1}^{(n)})$

在假设连续后验pdf可以由马尔可夫链近似的情况下, 等式3的连续后验pdf可以被重写为递归贝叶斯滤波分布的蒙特卡罗近似中离散样本的集合(注意, 等式3的积分现在是一个求和操作).

$p(X_t|Z_{1:t})\approx C^{-1}p(Z_t|X_t)\sum\limits_np(X_t|X_{t-1}^{(n)})$

马尔科夫链是使用随机游走算法(如Metropolis-Hastings)构建的, 我们将把它当作一个黑盒子来处理, 但稍后会更详细地看待. 为了通过一系列图像跟踪对象, MCMC被连续地应用于视频中的每个帧. 对于每个时间点, MCMC使用了表示上一时间点的pdf以及观察信息的马尔科夫链的信息和动态模型.  

假设我们使用MCMC来构建马尔可夫链, 代表视频中每个图像的后验pdf, 我们仍然需要跟踪问题(即每个球的坐标和它们的半径的大小)的一个实际答案. 点估计是从马尔可夫链计算出的单个多目标配置, 用作跟踪器的输出. 有几种计算点估计的方法, 其中一些可能根据情况更适合. 对于多目标跟踪, 通常计算多对象配置的各种参数的边界平均值来给出平滑和准确的答案. 

## Metropolis-Hastings MCMC

我们已经确定，解决多目标跟踪问题的关键在于找到递归的贝叶斯滤波分布, 该分布可以使用马尔可夫链的一组离散样本近似. 如果我们以某种方式预先知道递归的贝叶斯滤波分布, 那么近似它只是一个从中抽样的问题(当然, 忽略了我们已经知道我们试图近似的分布的事实). 

不幸的是，我们发现自己处于尝试找到未知的递归贝叶斯滤波分布的近似的困难处境下. 幸运的是, 这正是MCMC算法所要解决的问题. MCMC的思想是在使用马尔可夫链机制探索状态空间(可能的对象配置的空间)的同时生成样本. 建立链的机制是为了使链条在重要(高概率)区域花费更多的时间. Metropolis-Hastings(MH)算法是MCMC最流行的“标志”, 它以随机游走的方式探索状态空间. 事实上, MCMC的大多数变体可以解释为MH的特殊情况或扩展.

### 传统的Metropolis-Hastings

经典的MH算法是相当简单的. 从初始配置$X_0$开始, 通过从提议分布$q(X^* | X_{(n-1)})$进行采样生成新的样本$X^*$.  然后将样品作为第n个样本接受并添加到马尔科夫链, 或者拒绝, 并将先前的样本作为第n个样本添加到链中. 接受或拒绝拟议样本的决定取决于接受率a. 接受率衡量了样本质量随先前样品的提高, 被样本各自的可能性所测量. 它自动接受显示改进的样本, 以概率a接受其余的. 

对单个对象进行建模时, 提议分布与单对象状态演变相同. 为了使事情变得简单, 我们将台球的状态演变建模成球的先前位置, 并且用零均值高斯分布定义扰动. 当然，如果我们喜欢: 在运动模型中包含速度, 我们可以使用t-2的位置信息来更新高斯分布. 

$x_t = x_{t-1}+w_t \\ y_t=y_{t-1}+w_t \qquad w_t \sim\mathcal{N}(0, \sigma)\\ r_t=r_{t-1}+w_t $

跟踪多个对象(但仍然是固定数量的对象)使事情变得复杂一些. 在计算接受率时, 取消提议密度中的某些项使得接受率易于理解. 因此, 当场景包含多个对象时, 通常只会对一个目标进行跟踪. 这在MH算法中引入了额外的步骤, 即在扰乱了提议分布中的样本之前, 从目标提议分布中选择目标对象. 通常, 目标提议分布是对所有对象的均匀分布. 下面总结了任意(但固定)数量的对象的MH算法.

*对于每个时间点, 根据以下步骤 (其中, $N_{burn}$代表burn-in样本的数量, $N_{mix}$是在burn-in之后达到混合时间的样本数), 通过从抽取的$N=N_{burn}+N_{mix}$构建马尔科夫链来近似递归贝叶斯滤波分布.*

*通过从t-1时刻的马尔可夫链中选择一个样本来初始化MH采样器, 并根据状态演变来移动所有目标. 使用结果作为新链X0的种子.*

1. 从前一个样本的状态开始, $X^{*} = X^{n-1}$
2. 从目标提议分布中选择一个目标对象$m^*$
3. 从提议分布(状态演变)中抽取目标$m^*$的一个新配置, 记为$X^*$, 同时保持其他的对象不变
4. 计算接受率$a=\min(1, \frac{p(Z_t|X_t^*)}{p(Z_t|X_t)})$, 可以简化为$a=\min(1, \frac{p(Z_t|X_{t, m^*}^*)}{p(Z_t|X_{t,m^*})})$
5. 将第n个样本添加到马尔科夫链中. 

注意, 接受率只是目标台球的提议配置与目标台球的先前配置的似然之比. 这是因为我们已经定义了似然, 以便删除其他台球的似然, 因为他们的状态没有改变.

Metropolis-Hastings算法通过提出一次改变一个目标并自动接收增加总体似然性的样本来探索高可能性的区域, 同时拒绝以概率a降低总体似然性的样本. 然而, 我们需要注意, 导致较低可能性的样本仍然可能被添加到马尔科夫链, 尽管这种情况的机会随着提议分布的可能性变差而变得更糟. 这个特性使得MH算法不会被局限在最大值中.

## 什么是可逆跳跃?

为了使问题进一步复杂化, 对于多目标跟踪, 多目标配置的维度必须能够改变. 如果无法更改, 场景中的对象数量将被固定. **马尔科夫链中样本之间的维度变化**称为尺寸跳跃. 不幸的是, 传统的MCMC方法如MH不能适应维度跳跃. 但是可逆跳马尔科夫链蒙特卡罗(RJMCMC)可以, 这样就可以用不同数量的对象对场景建模. 

## RJMCMC扩展的Metropolis-Hastings

现在, 我们来看看RJMCMC如何扩展MH算法来处理可变维状态空间. 回想一下，为了从场景中插入和删除球, 我们必须能够在多对象配置$X_t$中插入和删除它们. 算法1的MH算法(并且如图11所示)仅适用于固定维度状态空间.

1995年, Peter J.Green提出了一种RJMCMC的方法, 它允许采样器构建一个跳跃维度的马尔可夫链. 这是通过定义一组称为可逆跳跃的动作来实现的. 在该方案中, 任何能够改变链条维度的变动必须是可逆的, 即必须能够在稍后的改变中恢复到先前的状态.

我们可以定义任何我们想要的RJMCMC改变类型，只要它们是可逆的(尽管有时候定义改变类型可能很困难). 这种灵活性使得RJMCMC非常强大. 对于我们的台球示例, 我们将定义一组典型的RJMCMC改变类型, 包括更新改变, 这相当于选择目标对象的经典MH算法过程, 并从状态演变中提出新配置. 改变集包括: {更新, 生成, 死亡, 合并和拆分}.

1. 更新: 类似于经典的Metropolis-Hastings算法, 选择目标对象, 并根据状态演变生成一个提议的配置. 状态空间的维度不变. 
2. 生成: 将新对象添加到多对象配置中. 状态空间的维度增大. 
3. 死亡: 从多对象配置中删除现有对象. 状态空间的维度减小.
4. 合并: 两个对象合并成一个对象. 状态空间的维度减小.
5. 拆分: 从单个对象创建两个对象. 状态空间的维度增加.

对于定义的改变类型, 我们现在可以给出用于RJMCMC多对象跟踪的算法. 要在马尔可夫链中生成新的样本, 第一步是从改变类型集中选择一个改变类型. 这通常通过从集合中均匀采样来完成. 然后, 根据选择的改变类型生成提议多对象配置$X^*$, 计算接受率, 并将提议$X^*$或先前的样本$X_{n-1}$添加到马尔可夫链中. 请注意, 经典的MH算法可以看作是仅选择更新改变的RJMCMC的特殊情况. 以下给出了RJMCMC多目标跟踪算法. 

*对于每个时间点, 根据以下步骤 (其中, $N_{burn}$代表burn-in样本的数量, $N_{mix}$是在burn-in之后达到混合时间的样本数), 通过从抽取的$N=N_{burn}+N_{mix}$构建马尔科夫链来近似递归贝叶斯滤波分布.*

*通过从t-1时刻的马尔可夫链中选择一个样本来初始化RJMCMC采样器, 并根据状态演变来移动所有目标. 使用结果作为新链X0的种子.*

1. 从前一个样本的状态开始, $X^{*} = X^{n-1}$
2. 从移动类型集合中选择一个改变类型(通过从改变类型分布$P_{movetype}$采样).
3. 应用所选择的改变. 这包含了选择一个目标对象或者几个目标对象(通过一个改变特定的目标提议分布$q_{target}$)并且提议一个新的配置$X^*$(通过一个改变特定的提议分布Q). 
4. 计算接受率, a. 不同改变类型的a的定义是不一样的. 
5. 将第n个样本添加到马尔科夫链中. 

### 关于接受率的思考

在经典的MH算法中, 接受率简化成所提出的配置的可能性与先前配置的可能性的比率. 但现在, 提出的和以前的配置可能不一样. 比较不同维度的可能性将是无意义的; 就像不是将一个圆圈与另一个圆圈进行比较, 现在我们试图将一个圆圈与球体进行比较. 为了克服这个问题, 如果我们尝试从m维空间移动到n维空间, 我们必须定义维度匹配函数$Fm\rightarrow n$和$Fn\rightarrow m$, 这使得我们能够从一个空间扩展到另一个空间, 反之亦然.

我们可以重写多对象配置, 将维度(或对象数)包含为$X_t = \{m, X_{m, t}\}$. 这样做, 当从m维空间移动到n维空间时, 接受率的完整表达如下:

$a_{m\rightarrow n}=\min\{1, \frac{p(n,X_n^*|Z)}{p(m,X_m|Z)}\times\frac{q_{target}(i^*|n)}{q_{target}(i^*|m)}\times\frac{Q_{n\rightarrow m}(X_m|i^*)}{Q_{m\rightarrow n(X_n^*|i^*)}}\times J_{F_{m\rightarrow n}}\}$

根据我们如何定义我们的改变, 上式的很多项可以取消.  如果我们通过从均匀分布中抽样来选择我们的改变类型, 则第二项取消(预先改变类型/ p$\times$改变类型). 

## 链的长度

确定马尔可夫链的适当长度并不容易. 如果链条太短, 则可能无法给出后验pdf的良好近似, 接近目标分布所需的样本数称为混合时间.  在达到混合时间之后添加额外的样品可能会稍微改善近似值, 但仍然花费计算时间, 因此可能不是有利的.

一些研究人员已经定义了统计测试, 以检查马尔科夫链是否已经稳定, 这可能表明已经达到混合时间. 此外, 在确定混合时间方面已经做了几次尝试, 但是这些测试中没有一个保证满意的结果. 实际上, 通常在实验上确定适当的链长度. 

放弃初始的预训练样本集可能是有用的, 以允许马尔科夫链稳定并避免从起始位置引入偏差.